services:
  caddy:
    image: caddy:latest
    container_name: caddy
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - reviewer-network
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    profiles: ["no-llm-api-key"]
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./scripts/start-ollama.sh:/start-ollama.sh
    entrypoint: ["/bin/bash", "/start-ollama.sh"]
    networks:
      - reviewer-network
    restart: unless-stopped
    env_file:
      - ./settings.env

  reviewer:
    build:
      context: ./reviewer
      dockerfile: ./Dockerfile
    container_name: reviewer
    env_file:
      - ./secrets.env
      - ./settings.env
    networks:
      - reviewer-network
    restart: unless-stopped
    environment:
      - TZ=UTC
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8080/health')",
        ]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      - caddy

volumes:
  ollama_data:
  caddy_data:
  caddy_config:

networks:
  reviewer-network:
    driver: bridge
